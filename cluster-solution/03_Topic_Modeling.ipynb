{"cells":[{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"9d643639-5184-4a0a-98c8-7ce59d340f02","showTitle":false,"title":""}},"source":["Get top key words for each recommendation cluster using latent dirichlet allocation model"]},{"cell_type":"code","execution_count":1,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7984996c-dee4-49e4-b2ae-c1d3dd0737bc","showTitle":false,"title":""}},"outputs":[],"source":["# load data\n","import pandas as pd\n","recommd_cluster = pd.read_csv('CMV_Reports_Article_Recommendations_df.csv')\n","# dfCluster = spark.sql(' select * from NAII.CMV_Reports_Article_Recommendations_dfCluster').toPandas()"]},{"cell_type":"code","execution_count":2,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"11849bca-7336-4dd2-b082-da50e422ec00","showTitle":false,"title":""}},"outputs":[],"source":["# load stop words\n","import spacy\n","import en_core_web_sm\n","nlp = spacy.load(\"en_core_web_sm\")\n","# nlp.Defaults.stop_words |= {\"year\",\"month\",\"week\",\"number\",\"veteran\",\"va\",\"committee\",\"program\",\"minority\",\"report\", 'dear'}\n","\n","local_stop_words = {\"year\",\"month\",\"week\",\"number\",\"veteran\",\"va\",\"committee\",\"program\",\"minority\",\"report\",'secretary', 'member', 'subcommittee', 'department', 'meeting', 'information', 'service', 'director', 'provide', 'center', 'concern', 'affair', 'advisory', 'need', 'american', 'meet', 'establish', 'organization','second','annual'\n","'include', 'annex', 'work', 'plan', 'issue', 'serve', 'health', 'review', 'group', 'support', 'specific', 'care', 'office', 'page', 'day', 'continue', 'factor', 'dear',\n","                           'recommend', 'recommendation', 'process', 'develop', 'implement'}\n","# import pickle\n","# with open('/dbfs/NAII/CMV Reports/stopwords_by_year', 'rb') as fp:\n","#     stopByYear = pickle.load(fp)\n","    \n","nlp.Defaults.stop_words |= local_stop_words"]},{"cell_type":"code","execution_count":3,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"3789affd-395e-4f0a-ae84-48ab1c9dcd0b","showTitle":false,"title":""}},"outputs":[],"source":["# lemmatization\n","def lemmatization(reports):\n","    # Tags I want to remove from the text\n","    removal= ['ADV','PRON','CCONJ','PUNCT','PART','DET','ADP','SPACE', 'NUM', 'SYM']\n","    stops = nlp.Defaults.stop_words\n","    \n","    summary = nlp(reports)\n","    proj_tok = [token.lemma_.lower() for token in summary if token.pos_ not in removal  and token.is_alpha]\n","#         proj_tok = [sym_spell.lookup(t, Verbosity.CLOSEST, max_edit_distance=2, include_unknown=True, ignore_token=r\"\\w+\\d\")[0].term for t in proj_tok]\n","    proj_tok = [w for w in proj_tok if w not in stops]\n","    \n","    return proj_tok"]},{"cell_type":"code","execution_count":4,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"439f1579-8ebb-4500-be23-6189394dbb93","showTitle":false,"title":""}},"outputs":[],"source":["# tokenize\n","def tokenized_corpus(df, cluster):\n","    clusterIdx = [i for i, y in enumerate(df['cluster']) if y == cluster]\n","    reports_text = [lemmatization(df['text'][i]) for i in clusterIdx]\n","    id2word = corpora.Dictionary(reports_text)\n","    # Create Corpus\n","#     texts = reports_text\n","    # Term Document Frequency\n","#     id2word.filter_extremes(no_below=1, no_above=0.95, keep_n=10000)\n","    corpus = [id2word.doc2bow(text) for text in reports_text]\n","    return reports_text, corpus, id2word"]},{"cell_type":"code","execution_count":5,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2d70fce4-774f-436b-936c-59e97d69e9c9","showTitle":false,"title":""}},"outputs":[],"source":["# fit lda model\n","def fit_lda(corpus, id2word, num_topics, alpha, eta, offset):\n","    lda_model = gensim.models.LdaModel(corpus=corpus,\n","                                       id2word=id2word,\n","                                       num_topics=num_topics,\n","                                       iterations = 300,\n","                                       chunksize = 2000,\n","                                       alpha=alpha, \n","                                       eta=eta, \n","                                       decay=0.5, \n","                                       offset=offset, \n","                                       eval_every=10,\n","                                       gamma_threshold=0.001, \n","                                       minimum_probability=0.01, \n","                                       random_state= 24, \n","                                       minimum_phi_value=0.01, \n","                                       per_word_topics=False)\n","    return lda_model"]},{"cell_type":"code","execution_count":6,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"d9713872-b004-4863-ac23-9c8a92620aa0","showTitle":false,"title":""}},"outputs":[],"source":["# get coherence score\n","def get_coherence(lda_model, reports_text, id2word):\n","    coherenceModelLda = CoherenceModel(model=lda_model, corpus = corpus, dictionary=id2word, coherence='u_mass')\n","#     coherenceModelLda = CoherenceModel(model=lda_model, texts = reports_text, dictionary=id2word, coherence='c_uci')\n","#     coherenceModelLda = CoherenceModel(model=lda_model, texts = reports_text, dictionary=id2word, coherence='c_v')\n","    coherenceLda = coherenceModelLda.get_coherence()\n","    return coherenceLda"]},{"cell_type":"code","execution_count":7,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"2be39770-794b-41b2-af17-b8584776e9ae","showTitle":false,"title":""}},"outputs":[],"source":["# parameters to be tuned:\n","def create_parameter_grid():\n","    # number of topic\n","    min_topics = 5\n","    max_topics = 15\n","    step_size = 3\n","    topic_n = range(min_topics, max_topics, step_size)\n","\n","    # Alpha\n","    alpha = list(np.arange(0.01, 1, 0.2))\n","    alpha.append('symmetric')\n","    alpha.append('asymmetric')\n","    #alpha.append('auto')s\n","    \n","    # eta\n","    eta = list(np.arange(0.01, 1, 0.2))\n","    eta.append('symmetric')\n","    #eta.append('auto')\n","\n","    # offset\n","    offset = [1, 1.25, 1.5, 2]\n","    return topic_n, alpha, eta, offset"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"b7c145a2-180c-4937-9103-b6a2e8007ab7","showTitle":false,"title":""}},"source":["Parameter tuning for LDA <br>\n","Use conherence score as the standard for choosing the best parameter values"]},{"cell_type":"code","execution_count":8,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"4fce8bf4-00f2-4019-bfc8-4f913623abbc","showTitle":false,"title":""}},"outputs":[],"source":["import tqdm\n","import numpy as np\n","import pandas as pd\n","from gensim.models.coherencemodel import CoherenceModel\n","import gensim\n","import gensim.corpora as corpora\n","model_results = { 'alpha':[], 'eta':[], 'offset':[], 'coherence':[], 'cluster': [],  'topic_terms': [], 'topic_terms_word_prob': []}"]},{"cell_type":"code","execution_count":9,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7e0f1a1c-03af-4900-80ac-8955cdb073f6","showTitle":false,"title":""}},"outputs":[],"source":["# start parameter tuning\n","topic_n, alpha, eta, offset = create_parameter_grid()\n","clusters = recommd_cluster['cluster'].unique()\n","iters = 0\n","# pbar = tqdm.tqdm(total=len(alpha)*len(eta)*len(offset)*len(clusters))\n","\n","for clu in clusters:\n","    reports_text, corpus, id2word = tokenized_corpus(recommd_cluster, clu)\n","    t_n = 1\n","    alp_m = 0.0\n","    e_m = 0.0\n","    off_m = 0.0\n","    lda_m = None\n","    topic_terms_word = None\n","    topic_terms_prob = None\n","    coherence = -99999999\n","    \n","    for alp in alpha:\n","        for e in eta:\n","            for off in offset:  \n","                lda_model = fit_lda(corpus, id2word, t_n, alp, e, off)\n","                coherence_score = get_coherence(lda_model, reports_text, id2word)\n","                iters += 1\n","                if coherence_score > coherence:\n","                    # update \n","                    coherence = coherence_score\n","                    alp_m = alp\n","                    e_m = e\n","                    off_m = off\n","                    topic_terms = lda_model.get_topic_terms(0, 20) # topic 0, first 20 terms\n","#                     topic_terms_word = [] \n","                    for i in range(len(topic_terms)):\n","                        topic_terms_word = [id2word[idt[0]] for idt in topic_terms]\n","                        topic_terms_word_prob = [idt[1] for idt in topic_terms]\n","#                             model = copy.deepcopy(lda_model)\n","#                 pbar.update(1)\n","\n","    \n","#     print(iters)   \n","    model_results['alpha'].append(alp_m)\n","    model_results['eta'].append(e_m)\n","    model_results['offset'].append(off_m)\n","    model_results['coherence'].append(coherence)\n","    model_results['cluster'].append(clu)\n","    model_results['topic_terms'].append(topic_terms_word)\n","    model_results['topic_terms_word_prob'].append(topic_terms_word_prob)\n","# pbar.close()"]},{"cell_type":"code","execution_count":11,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"22fcfe93-76ff-4223-b141-f52941470480","showTitle":false,"title":""}},"outputs":[],"source":["# save model\n","import pickle\n","with open('./recommendation_clusters_LDA', 'wb') as fp:\n","    pickle.dump(model_results, fp)\n","# with open('/dbfs/NAII/CMV Reports/recommendation_clusters_LDA', 'rb') as fp:\n","#     model_results = pickle.load(fp)"]},{"cell_type":"code","execution_count":12,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"6af8ba71-a3aa-488d-9704-2be4ff0d6d7d","showTitle":false,"title":""}},"outputs":[],"source":["topTermsDF = pd.DataFrame({\n","    'cluster': np.repeat(model_results['cluster'], [len(i) for i in model_results['topic_terms']]),\n","    'topTerms': [j for i in model_results['topic_terms'] for j in i],\n","    'termsProb': [j for i in model_results['topic_terms_word_prob'] for j in i]\n","})"]},{"cell_type":"code","execution_count":13,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"61c4c8ff-2442-4b2e-82bb-fcdaed39f99e","showTitle":false,"title":""}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>cluster</th>\n","      <th>topTerms</th>\n","      <th>termsProb</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17</td>\n","      <td>budget</td>\n","      <td>0.082911</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>17</td>\n","      <td>facility</td>\n","      <td>0.051858</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>17</td>\n","      <td>pay</td>\n","      <td>0.041507</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>17</td>\n","      <td>cost</td>\n","      <td>0.041507</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>17</td>\n","      <td>impact</td>\n","      <td>0.031156</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>729</th>\n","      <td>26</td>\n","      <td>goal</td>\n","      <td>0.016463</td>\n","    </tr>\n","    <tr>\n","      <th>730</th>\n","      <td>26</td>\n","      <td>fte</td>\n","      <td>0.016463</td>\n","    </tr>\n","    <tr>\n","      <th>731</th>\n","      <td>26</td>\n","      <td>original</td>\n","      <td>0.016463</td>\n","    </tr>\n","    <tr>\n","      <th>732</th>\n","      <td>26</td>\n","      <td>calendar</td>\n","      <td>0.016463</td>\n","    </tr>\n","    <tr>\n","      <th>733</th>\n","      <td>26</td>\n","      <td>achieve</td>\n","      <td>0.016463</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>734 rows × 3 columns</p>\n","</div>"],"text/plain":["     cluster  topTerms  termsProb\n","0         17    budget   0.082911\n","1         17  facility   0.051858\n","2         17       pay   0.041507\n","3         17      cost   0.041507\n","4         17    impact   0.031156\n","..       ...       ...        ...\n","729       26      goal   0.016463\n","730       26       fte   0.016463\n","731       26  original   0.016463\n","732       26  calendar   0.016463\n","733       26   achieve   0.016463\n","\n","[734 rows x 3 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["display(topTermsDF)"]},{"cell_type":"code","execution_count":14,"metadata":{"application/vnd.databricks.v1+cell":{"inputWidgets":{},"nuid":"7562529e-f4d9-42ee-9a35-63e19a9c5e7b","showTitle":false,"title":""}},"outputs":[],"source":["topTermsDF.to_csv('CMV_Reports_Article_Recommendations_clusterLDA.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"03_Topic_Modeling","notebookOrigID":677698861150809,"widgets":{}},"kernelspec":{"display_name":"env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"nbformat":4,"nbformat_minor":0}
